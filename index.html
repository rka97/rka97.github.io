<!DOCTYPE html>
<html lang="en-us">
<head>
	<meta name="generator" content="Hugo 0.86.0-DEV" />
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Ahmed&#39;s corner/</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="robots" content="all,follow">
    <meta name="googlebot" content="index,follow,snippet,archive">
    <link rel="stylesheet" href="https://www.akhaled.org/hugo-theme-console/css/terminal-0.7.1.min.css">
    <link rel="stylesheet" href="https://www.akhaled.org/hugo-theme-console/css/animate-3.7.2.min.css">
    <link rel="stylesheet" href="https://www.akhaled.org/hugo-theme-console/css/console.css">
    <link rel="stylesheet" href="https://www.akhaled.org/hugo-theme-console/css/theorems.css">
    
      <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
      <![endif]-->
       
      <link href="https://www.akhaled.org/index.xml" rel="alternate" type="application/rss+xml" title="Ahmed's corner" />
    <meta property="og:title" content="Ahmed&#39;s corner" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://www.akhaled.org/" />


<meta name="twitter:title" content="Ahmed&#39;s corner"/>
<meta name="twitter:description" content=""/>

<script>
  MathJax = {
  loader: {load: ['[tex]/tagformat']},
  tex: {
  inlineMath: [['$', '$'], ['\\(', '\\)']],
  displayMath: [['$$','$$'], ['\\[', '\\]']],
  processEscapes: true,
  processEnvironments: true,
  tags: 'ams',
  packages: {'[+]': ['tagformat']},
  tagformat: {
    number: (n) =>  n,
    id: (label) => label
    },
  macros: {
    br: ["\\left ( #1 \\right )", 1],
    Var: ["\\mathrm{Var}"],
    norm: ["\\left\\lVert#1\\right\\rVert", 1],
    sqn: ["{\\left\\lVert#1\\right\\rVert}^2", 1],
    abs: ["\\left\\lvert#1\\right\\rvert", 1],
    ec: ["\\mathbb{E} \\left \[ #1 \\right \]", 1],
    ecn: ["\\mathbb{E} \\left \[ \\| #1 \\|^2 \\right \]", 1],
    eca: ["\\mathbb{E} \\left \[ \\left \\lvert #1 \\right \\rvert \\right \]", 1],
    pr: ["\\\mathrm{Prob}\\left(#1\\right)", 1],
    ev: ["\\left \\langle #1 \\right \\rangle", 1],
    br: ["\\left ( #1 \\right )", 1],
    pbr: ["\\left \\{ #1 \\right \\} ", 1],
    floor: ["\\left \\lfloor #1 \\right \\rfloor", 1],
    dbtilde: ["\\accentset{\\approx}{#1}", 1],
    N: ["\\mathbb{N}"],
    Z: ["\\mathbb{Z}"],
    Q: ["\\mathbb{Q}"],
    R: ["\\mathbb{R}"],
    X: ["\\mathcal{X}"],
    E: ["\\mathbb{E}"],
    Snp: ["\\mathbb{S}^{n}_{+}"],
    Sn: ["\\mathbb{S}^{n}"],
    F: ["\\mathcal{F}"],
    A: ["\\mathcal{A}"],
    B: ["\\beta"],
    J: ["\\mathcal{J}"],
    G: ["\\mathcal{G}"],
    lc: ["\\mathop l"],
    C: ["\\mathbb{C}"],
    K: ["\\mathcal{K}"],
    lub: ["\\mathrm{lub}"],
    g: ["\\mathrm{glb}"],
    seq: ["\\subseteq"],
    e: ["\\varepsilon"],
    la: ["\\lambda"],
    om: ["\\omega"],
    Om: ["\\Omega"],
    de: ["\\delta"],
    mbf: ["\\mathbf"],
    es: ["\\emptyset"],
    mc: ["\\mathcal"],
    un: ["\\cup"],
    ic: ["\\cap"],
    spn: ["\\mathrm{span \\ }"],
    dm: ["\\mathrm{dim \\ }"],
    sgn: ["\\mathrm{ \ sign}"],
    Lm: ["\\mathcal{L}"],
    nll: ["\\mathrm{null}"],
    diag: ["\\mathrm{diag }"],
    row: ["\\mathrm{row}"],
    col: ["\\mathrm{col \\ }"],
    rng: ["\\mathrm{range \\ }"],
    dgr: ["\\mathrm{deg \\ }"],
    dist: ["\\mathrm{dist}"],
    Prob: ["\\mathrm{Prob}"],
    Lim: ["\\lim\limits"],
    Sum: ["\\sum\limits"],
    Pt: ["\\|P\\|"],
    dmn: ["\\mathrm{dom \\ }"],
    Prod: ["\\prod\limits"],
    Beta: ["\\beta"],
    Seq: ["\\mathrm{Seq }"],
    adj: ["\\mathrm{adj \\ }"],
    rank: ["\\mathrm{rank \\ }"],
    epi: ["\\mathrm{epi}"],
    tr: ["\\mathrm{tr}"],
    op: ["\\mathrm{op}"],
    prox: ["\\mathrm{prox}"],
    D: ["\\mathcal{D}"],
    eqdef: ["\\overset{\\text{def}}{=}"],
    var: ["\\mathrm{Var}"],
    cov: ["\\mathrm{cov}"],
    Var: ["\\mathrm{Var}"],
    Ber: ["\\mathrm{Ber}"],
    Bern: ["\\mathrm{Bern}"],
    tvar: ["\\mathrm{TVar}"],
    Binom: ["\\mathrm{Binom}"],
    Pois: ["\\mathrm{Pois}"],
    cO: ["\\mathcal{O}"]
    },

  },
  options:
  {
  skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
  };

  window.addEventListener('load', (event) => {
    document.querySelectorAll("mjx-container").forEach(function(x){
    x.parentElement.classList += 'has-jax'})
  });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<link rel="stylesheet" href="https://www.akhaled.org/hugo-theme-console/css/theorems.css">

</head>
<body class="terminal">
    <div class="container">
        <div class="terminal-nav">
          <header class="terminal-logo">
            <div class="logo terminal-prompt">
              
              
              <a href="https://www.akhaled.org" class="no-style site-name">Ahmed&#39;s corner</a>:~# 
              </div></header>
          <nav class="terminal-menu">
            <ul vocab="https://schema.org/" typeof="BreadcrumbList">
                
                <li><a href="https://www.akhaled.org/pdfs/cv.pdf" typeof="ListItem" name="CV">CV</a></li>

                <li><a href="https://scholar.google.com/citations?user=Bc3wOdsAAAAJ&amp;hl=en" typeof="ListItem" name="Scholar Profile">Scholar</a></li>

                <li><a href="https://github.com/rka97" typeof="ListItem" name="GitHub profile">GitHub</a></li>
                
            </ul>
          </nav>
        </div>
    </div>

    <div class="container " >
        

<script>
  MathJax = {
  loader: {load: ['[tex]/tagformat']},
  tex: {
  inlineMath: [['$', '$'], ['\\(', '\\)']],
  displayMath: [['$$','$$'], ['\\[', '\\]']],
  processEscapes: true,
  processEnvironments: true,
  tags: 'ams',
  packages: {'[+]': ['tagformat']},
  tagformat: {
    number: (n) =>  n,
    id: (label) => label
    },
  macros: {
    br: ["\\left ( #1 \\right )", 1],
    Var: ["\\mathrm{Var}"],
    norm: ["\\left\\lVert#1\\right\\rVert", 1],
    sqn: ["{\\left\\lVert#1\\right\\rVert}^2", 1],
    abs: ["\\left\\lvert#1\\right\\rvert", 1],
    ec: ["\\mathbb{E} \\left \[ #1 \\right \]", 1],
    ecn: ["\\mathbb{E} \\left \[ \\| #1 \\|^2 \\right \]", 1],
    eca: ["\\mathbb{E} \\left \[ \\left \\lvert #1 \\right \\rvert \\right \]", 1],
    pr: ["\\\mathrm{Prob}\\left(#1\\right)", 1],
    ev: ["\\left \\langle #1 \\right \\rangle", 1],
    br: ["\\left ( #1 \\right )", 1],
    pbr: ["\\left \\{ #1 \\right \\} ", 1],
    floor: ["\\left \\lfloor #1 \\right \\rfloor", 1],
    dbtilde: ["\\accentset{\\approx}{#1}", 1],
    N: ["\\mathbb{N}"],
    Z: ["\\mathbb{Z}"],
    Q: ["\\mathbb{Q}"],
    R: ["\\mathbb{R}"],
    X: ["\\mathcal{X}"],
    E: ["\\mathbb{E}"],
    Snp: ["\\mathbb{S}^{n}_{+}"],
    Sn: ["\\mathbb{S}^{n}"],
    F: ["\\mathcal{F}"],
    A: ["\\mathcal{A}"],
    B: ["\\beta"],
    J: ["\\mathcal{J}"],
    G: ["\\mathcal{G}"],
    lc: ["\\mathop l"],
    C: ["\\mathbb{C}"],
    K: ["\\mathcal{K}"],
    lub: ["\\mathrm{lub}"],
    g: ["\\mathrm{glb}"],
    seq: ["\\subseteq"],
    e: ["\\varepsilon"],
    la: ["\\lambda"],
    om: ["\\omega"],
    Om: ["\\Omega"],
    de: ["\\delta"],
    mbf: ["\\mathbf"],
    es: ["\\emptyset"],
    mc: ["\\mathcal"],
    un: ["\\cup"],
    ic: ["\\cap"],
    spn: ["\\mathrm{span \\ }"],
    dm: ["\\mathrm{dim \\ }"],
    sgn: ["\\mathrm{ \ sign}"],
    Lm: ["\\mathcal{L}"],
    nll: ["\\mathrm{null}"],
    diag: ["\\mathrm{diag }"],
    row: ["\\mathrm{row}"],
    col: ["\\mathrm{col \\ }"],
    rng: ["\\mathrm{range \\ }"],
    dgr: ["\\mathrm{deg \\ }"],
    dist: ["\\mathrm{dist}"],
    Prob: ["\\mathrm{Prob}"],
    Lim: ["\\lim\limits"],
    Sum: ["\\sum\limits"],
    Pt: ["\\|P\\|"],
    dmn: ["\\mathrm{dom \\ }"],
    Prod: ["\\prod\limits"],
    Beta: ["\\beta"],
    Seq: ["\\mathrm{Seq }"],
    adj: ["\\mathrm{adj \\ }"],
    rank: ["\\mathrm{rank \\ }"],
    epi: ["\\mathrm{epi}"],
    tr: ["\\mathrm{tr}"],
    op: ["\\mathrm{op}"],
    prox: ["\\mathrm{prox}"],
    D: ["\\mathcal{D}"],
    eqdef: ["\\overset{\\text{def}}{=}"],
    var: ["\\mathrm{Var}"],
    cov: ["\\mathrm{cov}"],
    Var: ["\\mathrm{Var}"],
    Ber: ["\\mathrm{Ber}"],
    Bern: ["\\mathrm{Bern}"],
    tvar: ["\\mathrm{TVar}"],
    Binom: ["\\mathrm{Binom}"],
    Pois: ["\\mathrm{Pois}"],
    cO: ["\\mathcal{O}"]
    },

  },
  options:
  {
  skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
  };

  window.addEventListener('load', (event) => {
    document.querySelectorAll("mjx-container").forEach(function(x){
    x.parentElement.classList += 'has-jax'})
  });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<link rel="stylesheet" href="https://www.akhaled.org/hugo-theme-console/css/theorems.css">


<figure style="float:right; max-width:25%;min-width:40px;">
    <img src="images/photo5.png" style="border-radius:3%" alt="Photo of me" />
    <!-- <figcaption style="text-align:center">At the <a href="https://en.wikipedia.org/wiki/Citadel_of_Qaitbay">citadel of Qaitbay</a>  </figcaption> -->
</figure>



<h1>About</h1>
<p><a href="mailto:ahmed.khaled@princeton.edu">ahmed . khaled @ princeton . edu</a></p>
<p>Welcome to my tiny corner of the internet! I&rsquo;m Ahmed, I work on optimization and machine learning. I&rsquo;m a second-year Ph.D. student in the ECE department at Princeton University, advised by Prof. <a href="https://sites.google.com/view/cjin/home">Chi Jin</a>. I am interested in optimization in machine learning, and in federated learning.</p>

    <p>In the past, I have been fortunate to intern at Meta AI, working with <a href="https://www.aarondefazio.com/">Aaron Defazio</a> in the summer of 2023. Before that, I interned in the group of Prof. <a href="https://richtarik.org/index.html">Peter Richtárik</a> at <a href="https://www.kaust.edu.sa/en/">KAUST</a> in the summers of 2019/2020, where I worked on the distributed &amp; stochastic optimization. Prior to that, I did some research on accelerating the training of neural networks by with Prof. <a href="https://scholar.google.com.eg/citations?user=YNxHCMwAAAAJ&amp;hl=en">Amir Atiya</a>.</p>





<h1>Publications and Preprints</h1>

<dt><a href="https://arxiv.org/abs/2305.16284">DoWG Unleashed: An Efficient Universal Parameter-Free Gradient Descent Method</a></dt>
<dd>Preprint (2023), <em>with <a href="https://sites.google.com/view/cjin/home">Chi Jin</a> and <a href="https://konstmish.com">Konstantin Mishchenko</a></em>. <a href="/static/dowg.bib">(bibtex)</a>.</dd>


<dt><a href="https://arxiv.org/abs/2209.02257">Faster federated optimization under second-order similarity</a></dt>
<dd>The 11th International Conference on Learning Representations (ICLR 2023), <em>with <a href="https://sites.google.com/view/cjin/home">Chi Jin</a></em>. <a href="/static/KJ2022FFSO.bib">(bibtex)</a>.</dd>

<dt><a href="https://openreview.net/pdf?id=AU4qHN2VkS">Better Theory for SGD in the Nonconvex World</a></dt>
<dd>Transactions on Machine Learning Research (TMLR) 2023, <em>with <a href="https://richtarik.org/index.html">Peter Richtárik</a></em>. <a href="/static/KR2020sgdnonconvex.bib">(bibtex)</a>. Original preprint  <a href="https://arxiv.org/abs/2002.03329">arXiv:2002.03329</a> on arXiv since 2020. </dd>

    <dt><a href="https://arxiv.org/abs/2206.07021">Federated Optimization Algorithms with Random Reshuffling and Gradient Compression</a></dt>
    <dd>Preprint (2022), <em>with <a href="https://scholar.google.com/citations?user=R-xZRIAAAAAJ&hl=ru">Abdurakhmon Sadiev</a>, <a href="https://grigory-malinovsky.github.io/">Grigory Malinovsky</a>, <a href="https://eduardgorbunov.github.io/">Eduard Gorbunov</a>, <a href="https://scholar.google.com/citations?user=OBbPecwAAAAJ&hl=en">Igor Sokolov</a>, <a href="https://burlachenkok.github.io/">Konstantin Burlachenko</a>, and <a href="https://richtarik.org/index.html">Peter Richtárik</a></em>. <a href="/static/sadiev22fedqrr.bib">(bibtex)</a>.</dd>

<dt><a href="https://arxiv.org/abs/2102.06704">Proximal and Federated Random Reshuffling</a></dt>
<dd>The 39th International Conference on Machine Learning (ICML 2022), <em>with <a href="https://konstmish.com">Konstantin Mishchenko</a> and <a href="https://richtarik.org/index.html">Peter Richtárik</a></em>. <a href="/static/MKR2021proxrr.bib">(bibtex)</a>.</dd>

<dt><a href="https://arxiv.org/abs/2111.11556">FLIX: A Simple and Communication-Efficient Alternative to Local Methods in Federated Learning</a></dt>
<dd>The 25th International Conference on Artificial Intelligence and Statistics (AISTATS 2022), with <a href="https://elnurgasanov.com/">Elnur Gasanov</a>, <a href="https://samuelhorvath.github.io/">Samuel Horváth</a>, and <a href="https://www.richtarik.org">Peter Richtárik</a>. <a href="/static/GKHR2022flix.bib">(bibtex)</a>.</dd>

<dt><a href="https://arxiv.org/abs/2006.05988">Random Reshuffling: Simple Analysis with Vast Improvements</a></dt>
<dd>Advances in Neural Information Processing Systems 33 (NeurIPS 2020), <em>with <a href="https://konstmish.com">Konstantin Mishchenko</a> and <a href="https://richtarik.org/index.html">Peter Richtárik</a></em>. <a href="/static/MKR2020rr.bib">(bibtex)</a>.</dd>

<dt><a href="https://arxiv.org/abs/1909.04746">Tighter Theory for Local SGD on Identical and Heterogeneous Data</a></dt>
<dd>The 23rd International Conference on Artificial Intelligence and Statistics (AISTATS) 2020, <em>with <a href="https://konstmish.com">Konstantin Mishschenko</a> and <a href="https://richtarik.org/index.html">Peter Richtárik</a></em>.  <a href="/static/KMR2020localsgd.bib">(bibtex)</a>. Extends the workshop papers (<a href="https://arxiv.org/abs/1909.04746v1">a</a>, <a href="https://arxiv.org/abs/1909.04715">b</a>).</dd>

    <dt><a href="https://arxiv.org/abs/2006.11573">Unified Analysis of Stochastic Gradient Methods for Composite Convex and Smooth Optimization</a></dt>
    <dd>Preprint (2020), <em>with <a href="https://othmanesebbouh.github.io/">Othmane Sebbouh</a>, <a href="https://www.maths.ed.ac.uk/~s1461357/">Nicolas Loizou</a>, <a href="https://gowerrobert.github.io/">Robert M. Gower</a>, and <a href="https://richtarik.org/index.html">Peter Richtárik</a></em>. <a href="/static/KSLGR2020unified.bib">(bibtex)</a>.</dd>


    <dt><a href="https://arxiv.org/abs/1912.09925">Distributed Fixed Point Methods with Compressed Iterates</a></dt>
    <dd>Preprint (2019), <em>with <a href="https://github.com/Selim78">Sélim Chraibi</a>, <a href="https://www.dmitry-kovalev.com/">Dmitry Kovalev</a>, <a href="https://richtarik.org/index.html">Peter Richtárik</a>, <a href="https://adil-salim.github.io/">Adil Salim</a>, and <a href="https://mtakac.com/">Martin Takáč</a></em>. <a href="/static/CKKRST2019distributed.bib">(bibtex)</a>.</dd>


<dt><a href="https://acm.org/doi/abs/10.1145/3341105.3373852">Applying Fast Matrix Multiplication to Neural Networks</a></dt>
<dd>The 35th ACM/SIGAPP Symposium On Applied Computing (ACM SAC) 2020, <em>with <a href="https://scholar.google.com.eg/citations?hl=en&amp;user=YNxHCMwAAAAJ">Amir F. Atiya</a> and <a href="https://scholar.google.com.eg/citations?user=AbVIlsoAAAAJ&amp;hl=en">Ahmed H. Abdel-Gawad</a></em>. <a href="/static/KAA2020fmm.bib">(bibtex)</a>.</dd>

</dl>

<h1>Workshop papers</h1>

<dt><a href="https://arxiv.org/abs/1909.04746v1">Better Communication Complexity for Local SGD</a></dt>
<dd>Oral presentation at the NeurIPS 2019 Workshop on Federated Learning for Data Privacy and Confidentiality, <em>with <a href="https://konstmish.com">Konstantin Mishschenko</a> and <a href="https://richtarik.org/index.html">Peter Richtárik</a></em>. <a href="/static/KMR2019localsgd.bib">(bibtex)</a>.</dd>
<dt><a href="https://arxiv.org/abs/1909.04715">First Analysis of Local GD on Heterogenous Data</a></dt>
<dd>NeurIPS 2019 Workshop on Federated Learning for Data Privacy and Confidentiality, <em>with <a href="https://konstmish.com">Konstantin Mishschenko</a> and <a href="https://richtarik.org/index.html">Peter Richtárik</a></em>. <a href="/static/KMR2019localgd.bib">(bibtex)</a>.</dd>
<dt><a href="https://arxiv.org/abs/1909.04716">Gradient Descent with Compressed Iterates</a></dt>
<dd>NeurIPS 2019 Workshop on Federated Learning for Data Privacy and Confidentiality, <em>with <a href="https://richtarik.org/index.html">Peter Richtárik</a></em>. <a href="/static/KR2019gdci.bib">(bibtex)</a>.</dd>


<h1>Talks</h1>
<dl><!--
         <dt><a href="https://sites.google.com/view/one-world-seminar-series-flow/archive?authuser=0#h.azhfwca3oax9">FLIX: A Simple and Communication-Efficient Alternative To Local Methods in Federated Learning</a></dt>
         <dd>Federated Learning One World Seminar (2022). <a href="https://www.youtube.com/watch?v=gzA6rXGloTM">Video</a>.</dd>
    -->

<dt><a href="https://sites.google.com/view/one-world-seminar-series-flow/archive?authuser=0#h.azhfwca3oax9">On the Convergence of Local SGD on Identical and Heterogeneous Data</a></dt>
<dd>Federated Learning One World Seminar (2020). <a href="https://www.youtube.com/watch?v=6ThWeKQyp8k&amp;feature=emb%5Ftitle">Video</a> and <a href="/static/FLOW_LocalSGD.pdf">Slides</a>.</dd>
</dl>























        <div class="footer">
    Powered by <a href="https://gohugo.io/">Hugo</a> with
    <a href="https://github.com/mrmierzejewski/hugo-theme-console/">Console Theme</a>. 
</div>

    </div>
  </body>
</html>
