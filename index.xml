<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ahmed&#39;s corner</title>
    <link>https://rka97.github.io/</link>
    <description>Recent content on Ahmed&#39;s corner</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://rka97.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>About</title>
      <link>https://rka97.github.io/main/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rka97.github.io/main/about/</guid>
      <description>ahmed . khaled @ princeton . edu
Welcome to my tiny corner of the internet! I&amp;rsquo;m Ahmed, I work on optimization and machine learning. I&amp;rsquo;m a first-year Ph.D. student in the ECE department at Princeton University. I have a Bachelor&amp;rsquo;s degree in Computer Engineering from Cairo University, Egypt.
Before joining Princeton, I was fortunate to intern in the group of Prof. Peter Richtárik at KAUST in the summers of 2019/2020, where I worked on the distributed &amp;amp; stochastic optimization.</description>
    </item>
    
    <item>
      <title>Papers</title>
      <link>https://rka97.github.io/main/papers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rka97.github.io/main/papers/</guid>
      <description>(In reverse order of preparation)
 Proximal and Federated Random Reshuffling Preprint (2021), with Konstantin Mishchenko and Peter Richtárik. (bibtex). Unified Analysis of Stochastic Gradient Methods for Composite Convex and Smooth Optimization Preprint (2020), with Othmane Sebbouh, Nicolas Loizou, Robert M. Gower, and Peter Richtárik. (bibtex). Random Reshuffling: Simple Analysis with Vast Improvements Advances in Neural Information Processing Systems 33 (NeurIPS 2020), with Konstantin Mishchenko and Peter Richtárik. (bibtex). Better Theory for SGD in the Nonconvex World Preprint (2020), with Peter Richtárik.</description>
    </item>
    
    <item>
      <title>Talks</title>
      <link>https://rka97.github.io/main/talks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rka97.github.io/main/talks/</guid>
      <description> On the Convergence of Local SGD on Identical and Heterogeneous Data Federated Learning One World Seminar (2020). Video and Slides.  </description>
    </item>
    
  </channel>
</rss>
